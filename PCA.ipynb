{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the datasets\n",
    "clinical_data = pd.read_csv('datasets/clinical_dataset.csv')\n",
    "lifestyle_data = pd.read_csv('datasets/lifestyle_dataset.csv')\n",
    "\n",
    "# Preprocessing the lifestyle dataset by dropping the output column\n",
    "Xlifestyle = lifestyle_data.drop('Heart Attack Risk', axis=1)\n",
    "Ylifestyle = lifestyle_data['Heart Attack Risk']\n",
    "\n",
    "# Preprocessing the clinical dataset by dropping the output column\n",
    "Xclinical = clinical_data.drop('output', axis=1)\n",
    "Yclinical = clinical_data['output']\n",
    "\n",
    "# Convert categorical columns to numeric using one-hot encoding before splitting\n",
    "Xlifestyle_encoded = pd.get_dummies(Xlifestyle, drop_first=True)\n",
    "Xclinical_encoded = pd.get_dummies(Xclinical, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1: Principle Component Analysis \n",
    "\n",
    "When to use: PCA is suitable when you have numerical data and want to capture the most variance in fewer dimensions.\n",
    "How it works: PCA transforms the data into new dimensions (principal components) that are linear combinations of the original features. The first few components capture the most variance in the data.\n",
    "Benefit: This method is often useful when working with models like Logistic Regression or KNN, as it reduces the feature space and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "Xlifestyle_encoded = pd.get_dummies(Xlifestyle, drop_first=True)\n",
    "Xclinical_encoded = pd.get_dummies(Xclinical, drop_first=True)\n",
    "\n",
    "# Standardize the data before applying PCA\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale lifestyle dataset\n",
    "Xlife_scaled = scaler.fit_transform(Xlifestyle_encoded)\n",
    "\n",
    "# Scale clinical dataset\n",
    "Xclinical_scaled = scaler.fit_transform(Xclinical_encoded)\n",
    "\n",
    "# Apply PCA to reduce dimensions to 10 components for lifestyle dataset\n",
    "pca_life = PCA(n_components=10)\n",
    "Xlife_pca = pca_life.fit_transform(Xlife_scaled)\n",
    "\n",
    "# Apply PCA to reduce dimensions to 10 components for clinical dataset\n",
    "pca_clinical = PCA(n_components=10)\n",
    "Xclinical_pca = pca_clinical.fit_transform(Xclinical_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy (Lifestyle): 0.6101179155572461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73      1691\n",
      "           1       0.40      0.20      0.27       938\n",
      "\n",
      "    accuracy                           0.61      2629\n",
      "   macro avg       0.53      0.52      0.50      2629\n",
      "weighted avg       0.56      0.61      0.57      2629\n",
      "\n",
      "MLP Accuracy (Clinical): 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        41\n",
      "           1       0.80      0.78      0.79        50\n",
      "\n",
      "    accuracy                           0.77        91\n",
      "   macro avg       0.77      0.77      0.77        91\n",
      "weighted avg       0.77      0.77      0.77        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elvis\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Split the lifestyle dataset into training and test sets\n",
    "Xlife_train, Xlife_test, Ylife_train, Ylife_test = train_test_split(Xlife_pca, Ylifestyle, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define and train the MLP classifier for lifestyle dataset\n",
    "mlp_life = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_life.fit(Xlife_train, Ylife_train)\n",
    "\n",
    "# Predictions and evaluation for MLP\n",
    "Ylife_pred_mlp = mlp_life.predict(Xlife_test)\n",
    "print(f'MLP Accuracy (Lifestyle): {accuracy_score(Ylife_test, Ylife_pred_mlp)}')\n",
    "print(classification_report(Ylife_test, Ylife_pred_mlp))\n",
    "\n",
    "# Same for the clinical dataset\n",
    "Xclinical_train, Xclinical_test, Yclinical_train, Yclinical_test = train_test_split(Xclinical_pca, Yclinical, test_size=0.3, random_state=42)\n",
    "mlp_clinical = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_clinical.fit(Xclinical_train, Yclinical_train)\n",
    "\n",
    "# Predictions and evaluation for MLP\n",
    "Yclinical_pred_mlp = mlp_clinical.predict(Xclinical_test)\n",
    "print(f'MLP Accuracy (Clinical): {accuracy_score(Yclinical_test, Yclinical_pred_mlp)}')\n",
    "print(classification_report(Yclinical_test, Yclinical_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy (Lifestyle): 0.6432103461392165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1691\n",
      "           1       1.00      0.00      0.00       938\n",
      "\n",
      "    accuracy                           0.64      2629\n",
      "   macro avg       0.82      0.50      0.39      2629\n",
      "weighted avg       0.77      0.64      0.50      2629\n",
      "\n",
      "SVC Accuracy (Clinical): 0.8351648351648352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        41\n",
      "           1       0.84      0.86      0.85        50\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.83      0.83      0.83        91\n",
      "weighted avg       0.83      0.84      0.83        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define and train the SVC classifier for lifestyle dataset\n",
    "svc_life = SVC(kernel='linear', random_state=42)\n",
    "svc_life.fit(Xlife_train, Ylife_train)\n",
    "\n",
    "# Predictions and evaluation for SVC\n",
    "Ylife_pred_svc = svc_life.predict(Xlife_test)\n",
    "print(f'SVC Accuracy (Lifestyle): {accuracy_score(Ylife_test, Ylife_pred_svc)}')\n",
    "print(classification_report(Ylife_test, Ylife_pred_svc,zero_division=1))\n",
    "\n",
    "# Same for the clinical dataset\n",
    "svc_clinical = SVC(kernel='linear', random_state=42)\n",
    "svc_clinical.fit(Xclinical_train, Yclinical_train)\n",
    "\n",
    "# Predictions and evaluation for SVC\n",
    "Yclinical_pred_svc = svc_clinical.predict(Xclinical_test)\n",
    "print(f'SVC Accuracy (Clinical): {accuracy_score(Yclinical_test, Yclinical_pred_svc)}')\n",
    "print(classification_report(Yclinical_test, Yclinical_pred_svc, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Insights:\n",
    "The clinical dataset performed better with 83.52% accuracy, whereas the lifestyle dataset achieved a lower accuracy of 64.32%.\n",
    "The lifestyle dataset's precision for class 1 is 100%, but with 0% recall, meaning the model did not correctly predict any instances of heart attack risk (1), which explains the low F1-score for that class.\n",
    "\n",
    "The clinical dataset had a much more balanced performance between precision and recall for both classes.\n",
    "Next Steps:\n",
    "\n",
    "Imbalanced Classes: The low recall for the lifestyle dataset suggests an issue with class imbalance, where the model is struggling to correctly predict the minority class. You can address this by:\n",
    "\n",
    "Using class weights in the SVC model (class_weight='balanced').\n",
    "Applying techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset.\n",
    "\n",
    "Model Tuning: Consider tuning hyperparameters such as C and kernel for SVC, or try different classifiers like Random Forest or Gradient Boosting to see if they handle the lifestyle data better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
